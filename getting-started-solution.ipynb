{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b7bb00-e7bb-4b89-91e9-f1e9a5e7067b",
   "metadata": {},
   "source": [
    "# Analisando dados com PySpark\n",
    "\n",
    "Neste notebook, utilizaremos o PySpark para exemplificar como:\n",
    "\n",
    "- Extrair dados de um arquivo\n",
    "- Transformar os dados para extrair as informações relevantes\n",
    "- Analisar as estatísticas de interesse\n",
    "\n",
    "Para isso, utilizaremos o [MovieLens](https://grouplens.org/datasets/movielens/), um banco de dados com avaliações de usuários para filmes cujos arquivos necessários para este notebook se encontram na pasta `./data/input`.\n",
    "\n",
    "Com base no dataset, queremos responder a seguinte pergunta: \n",
    "\n",
    "> **Quantos filmes foram lançados em cada ano do dataset?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b09133-7ccb-4acb-829f-6dd18f117694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2333b0d1-b595-46ae-9872-e88554eefcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3865c14d-1e2b-4137-bfcf-9ae694d06c91",
   "metadata": {},
   "source": [
    "# Spark\n",
    "\n",
    "## Inicializando uma SparkSession\n",
    "\n",
    "A `SparkSession` encapsula uma série de funcionalidades e contextos para utilizarmos nas aplicações do Spark, como:\n",
    "\n",
    "- SparkContext\n",
    "- SQLContext\n",
    "- HiveContext\n",
    "- Streaming Application\n",
    "\n",
    "Para criar uma `SparkSession`, utilizaremos os seguintes métodos:\n",
    "1. **Builder()** para definir as configurações da sessão\n",
    "2. **appName(**_nome_**)** para definir um nome da sessão\n",
    "3. **getOrCreate()** para criar uma sessão com tais configurações (caso uma sessão com as mesmas configurações já exista, ela será retornada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfdb701f-39ae-4bee-b152-cb87c0e3c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.Builder()\\\n",
    "    .appName('EscolaDNC.dados')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5852-603b-4cae-ac49-087bb5bb7ff5",
   "metadata": {},
   "source": [
    "## Extraindo os dados\n",
    "\n",
    "Os dados de entrada se encontram na pasta `input`. Note que os dados estão em múltiplos arquivos csv. Para isso, utilizaremos os seguintes métodos do módulo `SparkSession.read`:\n",
    "1. **format(**_formato_**)**: para definir o formato do arquivo \n",
    "2. **option(**_chave_, _valor_**)**: para definir possíveis configurações de leitura\n",
    "3. **load(**_caminho_do_arquivo_**)**: para carregar o arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe4609a2-4dde-445c-94e9-128be89adafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = spark.read\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .load(os.path.join(DATA_FOLDER, 'input', '*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d50a69b-ab7d-4fff-b5c2-843304d1c30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "| 129717|My Best Friend's ...|              Comedy|\n",
      "| 207796|The Aeronauts (2019)|Action|Adventure|...|\n",
      "| 142322|The Ark of the Su...|    Action|Adventure|\n",
      "| 196447|  Wolf's Hole (1987)|Adventure|Drama|H...|\n",
      "| 167090|A Year and Change...|        Comedy|Drama|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movies.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3e9ca9-6654-46e3-b79d-735082b06b60",
   "metadata": {},
   "source": [
    "## Transformando os dados\n",
    "\n",
    "Agora que temos um dataframe em mãos, podemos fazer transformações em suas colunas. Em particular, utilizaremos os seguintes métodos:\n",
    "\n",
    "1. **withColumnRenamed(**_nome_antigo_, _novo_nome_**)** para renomear a coluna `movieId` para `movie_id`\n",
    "2. **withColumn(**_nova_coluna_, _funcao_**)** para aplicar uma função em uma coluna\n",
    "3. **pyspark.sql.functions.regexp_extract(**_coluna_, _regexp_**)** para extrair o ano dofilme da coluna `title` (utilize a expressão regular `\\((\\d{4})\\)$`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04f83e46-b5fa-4964-aded-a68e79f8d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c2653fa-928c-4383-a146-6f92ea7f9185",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = df_movies\\\n",
    "    .withColumnRenamed('movieId', 'movie_id')\\\n",
    "    .withColumn(\"year\", f.regexp_extract(\"title\", '\\((\\d{4})\\)$', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68df6a0d-4690-436f-89d4-5e0fa99642a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+----+\n",
      "|movie_id|               title|              genres|year|\n",
      "+--------+--------------------+--------------------+----+\n",
      "|  129717|My Best Friend's ...|              Comedy|1998|\n",
      "|  207796|The Aeronauts (2019)|Action|Adventure|...|2019|\n",
      "|  142322|The Ark of the Su...|    Action|Adventure|1984|\n",
      "|  196447|  Wolf's Hole (1987)|Adventure|Drama|H...|1987|\n",
      "|  167090|A Year and Change...|        Comedy|Drama|2015|\n",
      "+--------+--------------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movies.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd98cb-42f7-480c-9c4f-dfd9673ba368",
   "metadata": {},
   "source": [
    "## Analisando os dados\n",
    "\n",
    "Uma das funcionalidades que facilita a análise de dados utilizando o Spark é o `SparkSQL`, em que podemos fazer consultas nos dados como se estivéssmos utilizando um banco de dados relacional.\n",
    "\n",
    "A utilização do `SparkSQL` pode ser feita através de 2 métodos:\n",
    "\n",
    "1. **DataFrame.createOrReplaceTempView(**_nome_**)** para criarmos uma view consultável a partir do dataframe\n",
    "2. **SessionSpark.sql(**_query_**)** para realizar a consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c7d98ed-fe10-4efe-8e39-2c8ce5e3db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.createOrReplaceTempView(\"MOVIES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c16bd9db-0ce1-44ef-b6c7-39f692021f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|year|n_movies|\n",
      "+----+--------+\n",
      "|2019|     993|\n",
      "|2018|    2032|\n",
      "|2017|    2373|\n",
      "|2016|    2488|\n",
      "|2015|    2512|\n",
      "|2014|    2406|\n",
      "|2013|    2173|\n",
      "|2012|    1978|\n",
      "|2011|    1838|\n",
      "|2010|    1691|\n",
      "|2009|    1724|\n",
      "|2008|    1632|\n",
      "|2007|    1498|\n",
      "|2006|    1446|\n",
      "|2005|    1255|\n",
      "|2004|    1171|\n",
      "|2003|    1028|\n",
      "|2002|    1023|\n",
      "|2001|     971|\n",
      "|2000|     929|\n",
      "+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_string = \"\"\"\n",
    "    SELECT \n",
    "        year, \n",
    "        COUNT(DISTINCT movie_id) AS n_movies \n",
    "    FROM MOVIES\n",
    "    GROUP BY year\n",
    "    ORDER BY year DESC\n",
    "\"\"\"\n",
    "spark.sql(sql_string).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
